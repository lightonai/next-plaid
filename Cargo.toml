[workspace]
members = ["next-plaid", "next-plaid-api", "next-plaid-onnx", "colgrep"]
resolver = "2"

[workspace.package]
version = "1.0.1"
edition = "2021"
license = "Apache-2.0"
repository = "https://github.com/lightonai/next-plaid"
homepage = "https://github.com/lightonai/next-plaid"
authors = ["Raphael Sourty, LightOn"]
documentation = "https://docs.rs/next-plaid"

[workspace.dependencies]
ndarray = { version = "0.16", features = ["rayon"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "2.0"
anyhow = "1.0"

[profile.release]
lto = true
codegen-units = 1
opt-level = 3

[profile.bench]
lto = true
codegen-units = 1
opt-level = 3

# The profile that 'cargo dist' will build with
[profile.dist]
inherits = "release"
lto = "thin"

# Config for 'cargo dist'
[workspace.metadata.dist]
# The preferred cargo-dist version to use in CI (Conditions for altering this include new features or bug fixes)
cargo-dist-version = "0.30.3"
# Custom release body with installation instructions
github-releases-body = """
## ColGREP (CLI)

Semantic code search for your codebase. Install with:

```bash
curl --proto '=https' --tlsv1.2 -LsSf https://github.com/lightonai/next-plaid/releases/latest/download/colgrep-installer.sh | sh
```

The installer automatically detects your platform and downloads the optimized binary (CoreML + Accelerate on Apple Silicon, Accelerate on Intel Mac).

## NextPlaid (API Server)

Multi-vector database with REST API. Run with Docker:

**CPU:**
```bash
docker pull ghcr.io/lightonai/next-plaid:cpu-1.0.0
docker run -p 8080:8080 -v ~/.local/share/next-plaid:/data/indices \
  ghcr.io/lightonai/next-plaid:cpu-1.0.0 \
  --host 0.0.0.0 --port 8080 --index-dir /data/indices \
  --model lightonai/answerai-colbert-small-v1-onnx --int8
```

**GPU (CUDA):**
```bash
docker pull ghcr.io/lightonai/next-plaid:cuda-1.0.0
docker run --gpus all -p 8080:8080 -v ~/.local/share/next-plaid:/data/indices \
  ghcr.io/lightonai/next-plaid:cuda-1.0.0 \
  --host 0.0.0.0 --port 8080 --index-dir /data/indices \
  --model lightonai/GTE-ModernColBERT-v1 --cuda
```
"""
# Allow custom modifications to release.yml (workflow_dispatch, crates.io publishing)
allow-dirty = ["ci"]
# CI backends to support
ci = "github"
# The installers to generate for each app
installers = ["shell", "powershell"]
# Target platforms to build apps for (Rust target-triple syntax)
targets = [
    "aarch64-apple-darwin",
    "x86_64-apple-darwin",
    "x86_64-unknown-linux-gnu",
    "x86_64-pc-windows-msvc",
]
# Whether to install an updater program
install-updater = false

# Custom runners for different targets
[workspace.metadata.dist.github-custom-runners]
aarch64-apple-darwin = "macos-14"
x86_64-apple-darwin = "macos-15"

# Apple Silicon builds with CoreML for model inference and Accelerate for vector search
[[workspace.metadata.dist.builds]]
targets = ["aarch64-apple-darwin"]
features = ["coreml", "accelerate"]

# Intel Mac builds with Accelerate for vector search
[[workspace.metadata.dist.builds]]
targets = ["x86_64-apple-darwin"]
features = ["accelerate"]
