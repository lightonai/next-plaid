# =============================================================================
# Docker Compose override for CUDA support
# Usage: docker compose -f docker-compose.yml -f docker-compose.cuda.yml up -d
# Or: make docker-up-cuda
# =============================================================================

services:
  next-plaid-api:
    build:
      context: .
      dockerfile: next-plaid-api/Dockerfile
      target: runtime-cuda
    volumes:
      - next-plaid-indices:/data/indices
      - next-plaid-models:/models
    environment:
      - RUST_LOG=info
      - NVIDIA_VISIBLE_DEVICES=all
    # Auto-download INT8 model from HuggingFace Hub
    command: ["--host", "0.0.0.0", "--port", "8080", "--index-dir", "/data/indices", "--model", "lightonai/GTE-ModernColBERT-v1-onnx", "--int8", "--cuda"]
    healthcheck:
      start_period: 120s  # Longer start period for model download + CUDA initialization
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 4G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  next-plaid-models:
