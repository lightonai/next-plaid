# =============================================================================
# Next-Plaid API Docker Compose
# =============================================================================
# Default configuration runs the CPU-only variant.
# See commented examples below for model and CUDA variants.
#
# Vector Database Storage:
#   Indices are persisted at ${NEXT_PLAID_DATA:-~/.local/share/next-plaid}
#   Each index is stored as a subdirectory: <data-dir>/<index-name>/
#   On container restart, existing indices are automatically loaded.
#
#   To customize the storage location:
#     export NEXT_PLAID_DATA=/path/to/data
#     docker compose up -d
#
#   Or create a .env file with:
#     NEXT_PLAID_DATA=/path/to/data
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # CPU-only variant (default) - smallest image, no encoding support
  # ---------------------------------------------------------------------------
  next-plaid-api:
    build:
      context: .
      dockerfile: next-plaid-api/Dockerfile
      # target: runtime-cpu  # Default target, can be omitted
    ports:
      - "8080:8080"
    volumes:
      # Persistent vector database storage
      # Default: ~/.local/share/next-plaid (XDG standard for user data)
      # Override with NEXT_PLAID_DATA environment variable
      - ${NEXT_PLAID_DATA:-~/.local/share/next-plaid}:/data/indices
    environment:
      - RUST_LOG=info
    healthcheck:
      test: ["CMD", "curl", "-f", "--max-time", "5", "http://localhost:8080/health"]
      interval: 15s
      timeout: 5s
      retries: 2
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 1G

  # ---------------------------------------------------------------------------
  # Model variant (CPU encoding) - uncomment to use
  # ---------------------------------------------------------------------------
  # next-plaid-api-model:
  #   build:
  #     context: .
  #     dockerfile: next-plaid-api/Dockerfile
  #     target: runtime-model
  #   ports:
  #     - "8080:8080"
  #   volumes:
  #     - ${NEXT_PLAID_DATA:-~/.local/share/next-plaid}:/data/indices
  #     - ./models:/models:ro  # Mount your ONNX models here
  #   environment:
  #     - RUST_LOG=info
  #   command: ["--host", "0.0.0.0", "--port", "8080", "--index-dir", "/data/indices", "--model", "/models/colbert"]
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "--max-time", "5", "http://localhost:8080/health"]
  #     interval: 15s
  #     timeout: 5s
  #     retries: 2
  #     start_period: 30s  # Longer start period for model loading
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 16G
  #       reservations:
  #         memory: 4G

  # ---------------------------------------------------------------------------
  # CUDA variant (GPU encoding) - uncomment to use
  # Requires: NVIDIA Container Toolkit (nvidia-docker2)
  # ---------------------------------------------------------------------------
  # next-plaid-api-cuda:
  #   build:
  #     context: .
  #     dockerfile: next-plaid-api/Dockerfile
  #     target: runtime-cuda
  #   ports:
  #     - "8080:8080"
  #   volumes:
  #     - ${NEXT_PLAID_DATA:-~/.local/share/next-plaid}:/data/indices
  #     - ./models:/models:ro  # Mount your ONNX models here
  #   environment:
  #     - RUST_LOG=info
  #     - NVIDIA_VISIBLE_DEVICES=all
  #   command: ["--host", "0.0.0.0", "--port", "8080", "--index-dir", "/data/indices", "--model", "/models/colbert", "--cuda"]
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "--max-time", "5", "http://localhost:8080/health"]
  #     interval: 15s
  #     timeout: 5s
  #     retries: 2
  #     start_period: 60s  # Longer start period for CUDA initialization
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 16G
  #       reservations:
  #         memory: 4G
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]
