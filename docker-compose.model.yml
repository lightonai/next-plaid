# =============================================================================
# Docker Compose override for model support (CPU encoding)
# Usage: docker compose -f docker-compose.yml -f docker-compose.model.yml up -d
# Or: make docker-up-model
#
# Vector Database Storage:
#   Indices are persisted at ${NEXT_PLAID_DATA:-~/.local/share/next-plaid}
#   Override with: export NEXT_PLAID_DATA=/path/to/data
# =============================================================================

services:
  next-plaid-api:
    build:
      context: .
      dockerfile: next-plaid-api/Dockerfile
      target: runtime-model
    volumes:
      # Persistent vector database storage (default: ~/.local/share/next-plaid)
      - ${NEXT_PLAID_DATA:-~/.local/share/next-plaid}:/data/indices
      # Named volume for model cache (auto-downloaded from HuggingFace)
      - next-plaid-models:/models
    # Auto-download INT8 model from HuggingFace Hub
    command: ["--host", "0.0.0.0", "--port", "8080", "--index-dir", "/data/indices", "--model", "lightonai/GTE-ModernColBERT-v1-onnx", "--int8"]
    healthcheck:
      start_period: 120s  # Longer start period for model download + loading
    deploy:
      resources:
        limits:
          memory: 16G
        reservations:
          memory: 4G

volumes:
  next-plaid-models:
