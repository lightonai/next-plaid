[package]
name = "next-plaid-onnx"
version.workspace = true
edition.workspace = true
description = "Fast ColBERT multi-vector encoding using ONNX Runtime"
license.workspace = true
repository.workspace = true
homepage.workspace = true
authors.workspace = true
readme = "README.md"
keywords = ["colbert", "onnx", "embeddings", "encoding", "multi-vector"]
categories = ["science", "algorithms"]

[lib]
name = "next_plaid_onnx"
path = "src/lib.rs"
crate-type = ["lib", "cdylib"]


[features]
default = []                # CPU by default - works everywhere out of the box
cuda = ["ort/cuda"]
tensorrt = ["ort/tensorrt"]
coreml = ["ort/coreml"]
directml = ["ort/directml"]
python = ["pyo3", "numpy"]

[dependencies]
# ort with download-binaries handles everything automatically:
# - Downloads correct ONNX Runtime for your platform
# - CPU works out of the box
# - Enable cuda/tensorrt/coreml/directml features for GPU acceleration
# Using load-dynamic for better compatibility across systems
ort = { version = "2.0.0-rc.11", features = ["ndarray", "load-dynamic"] }
tokenizers = { version = "0.21.1", default-features = false, features = [
    "onig",
] }
ndarray = "0.16"
anyhow = "1.0"
glob = "0.3"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
pyo3 = { version = "0.23", features = ["extension-module"], optional = true }
numpy = { version = "0.23", optional = true }
rayon = "1.10"
