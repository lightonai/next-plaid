[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "pylate-onnx-export"
version = "0.8.5"
description = "Export HuggingFace ColBERT models to ONNX format for Rust inference"
readme = "README.md"
license = { text = "Apache-2.0" }
requires-python = ">=3.10,<3.13"
authors = [{ name = "Raphael Sourty, LightOn", email = "contact@lighton.ai" }]
keywords = [
    "colbert",
    "onnx",
    "embeddings",
    "transformers",
    "information-retrieval",
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: Apache Software License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
dependencies = [
    "pylate>=1.3.3",
    "torch>=2.0.0",
    "transformers>=4.30.0",
    "safetensors>=0.4.0",
    "onnx>=1.14.0",
    "onnxruntime>=1.16.0",
    "numpy>=1.24.0",
    "huggingface-hub>=0.20.0",
]

[project.optional-dependencies]
dev = ["pytest>=7.0.0", "ruff>=0.1.0"]

[project.scripts]
pylate-onnx-export = "colbert_export.cli:main"
colbert-quantize = "colbert_export.cli:quantize_main"

[project.urls]
Homepage = "https://github.com/lightonai/next-plaid"
Repository = "https://github.com/lightonai/next-plaid"
Documentation = "https://github.com/lightonai/next-plaid/tree/main/onnx"

[tool.setuptools.packages.find]
where = ["src"]

[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = ["E", "F", "I", "W"]
ignore = ["E501"]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
markers = ["slow: marks tests as slow (deselect with '-m \"not slow\"')"]
